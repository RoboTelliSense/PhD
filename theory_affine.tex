\include{begin_article}
\title{Affine Warping in $\mathbb{R}^2$}
\author{Salman Aslam\\ Georgia Institute of Technology}
\date{}
\include{figs/inkscapeLatex}
\begin{document}
\maketitle
\rule[0pt]{\textwidth}{1pt}
\tableofcontents
\rule[0pt]{\textwidth}{1pt}
%================================
\section{Introduction}
%================================
In many situations, it is necessary to track a visual target that is undergoing deformations.  Several targets of interest fall in this category, particularly non-rigid targets such as humans.  Even rigid objects can undergo severe deformation in a matter of seconds as shown in Figure~\ref{Fig:PETS2001_deformation}.  


								\begin{figure}
								\centering
								\subfigure[Frame 770.]{\includegraphics[width=0.45\textwidth]{figs/PETS2001_00770.jpg}}
								\subfigure[Frame 1770.]{\includegraphics[width=0.45\textwidth]{figs/PETS2001_01770.jpg}}
								\caption{Over time, even rigid objects can undergo severe deformations such as the car in these images from the PETS2001 dataset.}
								\label{Fig:PETS2001_deformation}
								\end{figure}

In such cases, using a rigid rectangular bounding box to represent the target will inevitably lead to inclusion of background pixels in the matching process.  This can easily lead to tracker drift, particularly if the tracker is also trying to learn the appearance model of the target.

We now show how to use affine warping of the rectangular bounding box so that it more closely captures the outline of the target of interest.  This minimizes inclusion of background pixels in the matching process and leads to more robust tracking.

%================================
\section{Theory}
%================================
Table \ref{table:2Dtransformations} shows different kinds of 2D linear transformations.  Every transformation generalizes the transformation below it in the table.  In this report, we are interested in the 2D affine transform since it is flexible enough to account for most distortions in real images.

								\begin{table}[t]
								\centering
								\begin{tabular}{| l | c | c | p{2.5in} |}
								\hline
								Transformation & DoF & Matrix & Distortion\\ \hline 
								& & & \\ Projective & 8 & $\ProjMatrix$ & any arbitrary quadrilateral as long as no three points are collinear\\  & & & \\ \hline
								& & & \\ Affine & 6 & $\AffMatrix$ & rotation and non-isotropic scaling\\  & & & \\ \hline
								& & & \\ Similarity & 5 & $\SimMatrix$ & scaling and rigid motion\\  & & & \\ \hline
								& & & \\ Euclidean & 4 & $\EucMatrix$ & rigid motion (rotation, translation) \\  & & & \\ \hline
								\end{tabular}\
								\caption{2D transformations}
								\label{table:2Dtransformations}
								\end{table}

The affine transform\footnote{The notation adopted by some books for the affine transform is,

\begin{equation}
\begin{array}{llllllll}
X &= ax + by + e\\
Y &= cx + dy + f
\end{array}
\label{Eq:AffineDecomposition}
\end{equation}

where the input coordinate (x,y) has been transformed through 6 affine parameters, $a, b, c, d, e, f$ to the output coordinate $(X,Y)$.  Instead of $e$ and $f$, we will be using $t_x$ and $t_y$ respectively.}
 is given by,

\begin{equation}
\begin{array}{cllll}
\left[\begin{array}{l}\acute{x}\\\acute{y}\\1\end{array}\right]   &=& \AffMatrix \left[\begin{array}{l}x\\y\\1\end{array}\right]\\
\mathbf{\acute{x}} &=& \left[\begin{array}{cccc}\mathbf{A} & \mathbf{t}\\\mathbf{0}^T & 1\end{array}\right] \mathbf{x}\\
&=& \mathbf{A}\mathbf{x} + \mathbf{t}\\
&=& \mathbf{H}_A \mathbf{x}\\
\end{array}
\label{Eqn:top_level}
\end{equation}

$t_x$ and $t_y$ are translations in the $x$ and $y$ directions respectively and $\mathbf{H}_A$ is the affine transformation matrix.  The matrix $\mathbf{A}$ above can always be decomposed using the SVD decomposition as the product of orthonormal matrix $\mathbf{U}$ containing the eigenvectors of $\mathbf{A}\mathbf{A}^T$, orthonormal matrix $\mathbf{V}$ containing the eigenvectors  $\mathbf{A}^T\mathbf{A}$ and a diagonal matrix $\mathbf{S}$ containing the eigenvalues of $\mathbf{A}$~\cite{2004_BOOK_CG_Hartley}:

\begin{equation}
\begin{array}{llllllll}
\mathbf{A} &= \left[\begin{array}{lll}a & b \\ c & d\\ \end{array}\right] \\
&=\mathbf{U}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t} \\
&={\color{blue}(\mathbf{U}\mathbf{V}^t)}{\color{red}\mathbf{V}}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t}\\
&={\color{blue}\mathbf{R}(\theta)}{\color{red}\mathbf{R}(-\phi)}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{R} (\phi)}\\
&={\color{blue}\RotMatrixTheta}{\color{red}\RotMatrixminusPhi}{\color{darkgreen}\EigenvalueMatrix}{\color{red}\RotMatrixPhi}\\\\
\end{array}
\label{Eq:AffineDecomposition}
\end{equation}

${\color{blue}\mathbf{U}\mathbf{V}^t}$ is an orthogonal matrix since $({\color{blue}\mathbf{U}\mathbf{V}^t})^t =({\color{blue}\mathbf{U}\mathbf{V}^t})^{-1}$.  Therefore, without loss of generality, it can be written as a rotation matrix.  Of the possible 6 DOFs (degrees of freedom) of the affine transformation, the 4 DOFs in $\mathbf{A}$, i.e., ($a, b, c$, $d$) have been replaced with $(\theta, \lambda_1, \lambda_2, \phi)$.

The affine matrix $\mathbf{A}$ can therefore be viewed as a succession of the following 4 steps:

\begin{enumerate} 
\item Rotation by angle $\phi$ 
\item This rotation is followed by a scaling of $\lambda_1$ and $\lambda_2$ in the rotated $x$ and $y$ directions
\item A rotation by angle -$\phi$ which brings the scaled object back to its original orientation
\item A rotation by angle $\theta$
\end{enumerate}

\subsection{\underline{Converting $(a, b, c, d)$ to $(\theta, \lambda_1, \lambda_2, \phi)$}}
%-------------------------------------------------
In several cases, the affine parameters are given in the form of $(a, b, c, d)$.  However, it is difficult to get a physical intuition when the parameterization is done in this form.  In such cases, converting to $(\theta, \lambda_1, \lambda_2, \phi)$ helps in getting an insight into how the object of interest is being deformed.  For this step, first compute the SVD decomposition $\mathbf{A}=\mathbf{U}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t}$.  

The first parameter, angle $\phi$, is computed as follows,

%%%CAUTION: RECONCILE THIS WITH CODE%%%
\begin{equation}
\begin{array}{ccccll}
&{\color{red}\mathbf{R}(\phi)}&=&{\color{red}\mathbf{V}^T}\\
\Rightarrow &{\color{red}\RotMatrixPhi} &=& \left[\begin{array}{llll}v_{1,1} &v_{2,1}\\v_{1,2} & v_{2,2}\end{array}\right]\\
\end{array}
\end{equation}

Therefore,

\begin{equation}
\boxed{\phi = \tan^{-1}\frac{v_{1,2}}{v_{1,1}}}
\end{equation}

The second and third parameters, scaling factors $\lambda_1$ and $\lambda_2$, are computed as follows,

\begin{equation}
\begin{array}{ccccc}
&{\color{darkgreen}\EigenvalueMatrix} &=&{\color{darkgreen}\mathbf{S}}\\
&&=&\left[\begin{array}{cccc}s_{1,1} & 0\\0 &s_{2,2}\end{array}\right]\\
\end{array}
\end{equation}

Therefore,

\begin{equation}
\boxed{
\begin{array}{cccc}
\Rightarrow \lambda_1 &=&  s_{1,1}\\
\Rightarrow \lambda_2 &=& s_{2,2}
\end{array}}
\end{equation}

The fourth parameter, angle $\theta$, is computed as follows,  

\begin{equation}
\begin{array}{ccccc}
{\color{blue}\mathbf{R}(\theta)} &=&  {\color{blue}\mathbf{U}\mathbf{V}^T}\\
{\color{blue}\RotMatrixTheta} &= &\left[\begin{array}{llll}u_{1,1} & u_{1,2}\\u_{2,1} & u_{2,2}\end{array}\right]\left[\begin{array}{llll}v_{1,1} & v_{2,1}\\v_{1,2} & v_{2,2}\end{array}\right] \\
\end{array}
\end{equation}


Therefore,

\begin{equation}
\boxed{\theta = \tan^{-1}\frac{u_{2,1}v_{1,1} + u_{2,2}v_{1,2}}{u_{1,1}v_{1,1} + u_{1,2}v_{1,2}}}
\end{equation}

The code for this step is given in Listing~\ref{lst:UTIL_2D_affine_abcdxy_to_tllpxy}.

\subsection{\underline{Converting  $(\theta, \lambda_1, \lambda_2, \phi)$ to $(a, b, c, d)$}}
%-------------------------------------------------
In visual tracking, the initial target planar bounding region is more intuitively expressed in terms of $(\theta, \lambda_1, \lambda_2, \phi)$ than in terms of $(a, b, c, d)$.  However, the actual affine warp is more easily carried out using matrix multiplication for which we need $(a, b, c, d)$.  This can be done by multiplying out all the terms in Equation~\ref{Eq:AffineDecomposition} to get

\begin{equation}
\boxed{
\begin{array}{llll}
a &= (\lambda_2) p + (\lambda_1) q\\
b &= (\lambda_2) s  - (\lambda_1) r \\
c &= (\lambda_2) r  - (\lambda_1) s \\
d &= (\lambda_2)q + (\lambda_1) p
\end{array}}
\label{Eqn:tllpxy_to_abcdxy}
\end{equation}

								\begin{figure}
								\centering
								\fbox{
								\includegraphics[width=0.75\textwidth]{figs/GRAPHICS_2D_left_turn.pdf}
								}
								\caption{Turning clockwise (left turn) in $\mathbb{R}^2$.}
								\label{fig:left_turn}
								\end{figure}


%\begin{equation}
%\begin{array}{llll}
%\mathbf{A} &= \left[\begin{array}{lll}a & b \\ c & d\\ \end{array}\right]\\
%&=\bigMatrixTwo
%\end{array}
%\end{equation}

where temporary variables $p, q, r, s$ are computed from angles $\theta$ and $\phi$ using,

\begin{equation*}
\begin{array}{llll}
\mathrm{ccc} &= \cos(\theta) \cos^2(\phi)\\
\mathrm{ccs} &= \cos(\theta) \cos(\phi) \sin(\phi)\\
\mathrm{css} &= \cos(\theta) \sin^2(\phi)\\
\mathrm{scc} &= \sin(\theta) \cos^2(\phi) \\
\mathrm{scs} &= \sin(\theta) \cos(\phi) \sin(\phi)\\
\mathrm{sss} &= \sin(\theta) \sin^2(\phi)\\
p   &=  \mathrm{css} - \mathrm{scs}\\
q   &=  \mathrm{ccc} + \mathrm{scs}\\
r   &= \mathrm{ccs} + \mathrm{sss}\\
s   &=  \mathrm{ccs} - \mathrm{scc}\\
\end{array}
\end{equation*}

The code for this step is given in Listing~\ref{lst:UTIL_2D_affine_tllpxy_to_abcdxy}.

%================================
\section{Experiments}
%================================
We conduct the following 2 experiments:

\begin{enumerate}
\item Experiment 1: Forward affine transform to extract object of interest from larger image
\begin{enumerate}
\item Manually initialize an object of interest using rigid-parameter initialization.
\item Convert rigid-parameter initialization to affine-parameter initialization.
\item Warp arbitrary sized grid using affine-parameter initialization to sample object of interest
\item Compute pixel intensities at warped grid-points.
\end{enumerate}
\item Experiment 2: Inverse affine transform to warp feature points on larger image to warped image
\end{enumerate}


								\begin{figure}
								\centering
								\subfigure[An initial zero-centered reference 33x33 grid is affinely warped to sample an object of interest.  Notice that the density of grid points is greater in the horizontal direction.]{\fbox{\includegraphics[width=0.65\textwidth]{figs/dataset_Dudek_00001_sampled2.pdf}}}
								\subfigure[Warped 33x33 output for parameters shown in the left figure.]{\includegraphics[width=0.25\textwidth]{figs/dataset_Dudek_00001_sampled3.pdf}}
								\subfigure[Different affine parameters will produce different 33x33 outputs.]{\includegraphics[width=0.65\textwidth]{figs/affineCandidates.pdf}}
								\caption{Dudek dataset, frame 1, demonstration of affine warping.  The dimensions of the object of interest, the face, are 110x130 (width x height).  The warped output is 33x33.}
								\label{Fig:affine_warping}
								\end{figure}

The source code for these steps is given in Listing~\ref{lst:demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation}.

%----------------------------------
\subsection{Experiment 1: Forward affine transform}
%----------------------------------
In this experiment, our goal is to extract an object of interest from a larger image.

\subsubsection{Manually initialize an object of interest using rigid-parameter initialization}
%------------------------------------------------------------
An object of interest in an image can be manually specified by drawing a bounding box around it, and then rotating the bounding box so that it reasonably encloses the object.  This step is relatively straightforward to do in standard image processing software.  In most cases, this rigid representation, as opposed to an affine representation, will suffice to reasonably enclose the object of interest for the purposes of initialization.  This requires 5 parameters for complete specification:

\begin{enumerate}
\item $t_x$, bounding box center x coordinate
\item $t_y$, bounding box center y coordinate
\item $w$, width of bounding box
\item $h$, height of bounding box
\item $\theta$, rotation angle of bounding box in radians.  In the cartesian coordinate system, a positive $\theta$ corresponds to counter-clockwise direction.  This can be verified quickly since a $90^{\circ}$ left turn for a vector $(x,y)^T$ in $\mathbb{R}^2$ is given by $(-y,x)^T$.  This is obtained using,

\begin{equation}
\left[\begin{array}{ccc}
-y 
\\ 
x
\end{array}
\right]=
\left[
\begin{array}{rrr}
\cos(90^{\circ}) & -\sin(90^{\circ}) \\
\sin(90^{\circ}) & \cos(90^{\circ})
\end{array}
\right]
\left[\begin{array}{ccc}
x 
\\ 
y
\end{array}
\right]
\end{equation}

								\begin{figure}[t]
								\centering
								\subfigure[Input image with given feature points.]{\includegraphics[width=0.65\textwidth]{figs/dataset_Dudek_00001_feature_points.pdf}}\\
								\subfigure[Inverse affine mapping of feature points.]{\includegraphics[width=0.25\textwidth]{figs/dataset_Dudek_00001_feature_points_inverse_warped.pdf}}
								\caption{An input image with given feature points.}
								\label{fig:original_feature_points}
								\end{figure}


The term "left turn" is commonly used in computer graphics.  In  $\mathbb{R}^2$, it corresponds to a counter-clockwise rotation.  In images, where the $y$ coordinate normally decreases vertically downwards, a left turn is given by $(y,-x)^T$.  Notice that $(x,y)^T(-y,x) = (x,y)^T(y,-x) = 0$, and therefore both $ (-y,x)^T$ and $(y,-x)^T$ are orthogonal to $(x,y)^T$.  See Figure~\ref{fig:left_turn} for a graphical representation.
\end{enumerate}

As an example, consider Figure~\ref{Fig:affine_warping}.  We are interested in segmenting the face.  The initial parameters are: $t_x=188, t_y=192, w=110, h=130, \theta=-4.58^\circ$.  Note that we specify angles in radians.  $\theta$ is written here in degrees for clarity.  Moreover, notice that the bounding box is rotated in the counter-clockwise direction.  Since the y axis increases downwards, $\theta$ is negative.

\subsubsection{Convert rigid-parameter initialization to affine-parameter initialization}
%------------------------------------------------------------
Once we have an initial rigid representation of the object of interest, we can transform this representation into an affine representation.  Since the affine representation allows for scaling, we can scale the object and obtain its segmentation in scaled form.  For instance, in Figure~\ref{Fig:affine_warping}, the dimensions of the object of interest are 110x130.  However, for computational efficiency, we want the dimensions to be 33x33.  The affine parameters then become $\theta=-4.58^\circ, \lambda_1=110/32=3.4375, \lambda_2=130/32=4.0625, \phi=0^\circ, t_x=188, t_y=192$.  \footnote{Notice that we have divided by 32 instead of 33.  The reason is that the grid used in~\cite{2008_JNL_subspaceTRK_Ross} is 32x32 and they have accordingly used a divisor of 32.  In our case, for RVQ we require an odd dimensional grid due to the way the closed source codebook encoding software, gen.exe is setup.  Therefore, we pick a 33x33 grid.  Not changing the divisor to 33 was an oversight but this omission is expected to have minimal effect on results.}

\subsubsection{Warp arbitrary sized grid using affine-parameter initialization to sample object of interest}
%------------------------------------------------------------
In this step, the affine parameters $(\theta, \lambda_1, \lambda_2, \phi, t_x, t_y)$ computed above are changed to $(a, b, c, d, t_x, t_y)$ using Equation~\ref{Eqn:tllpxy_to_abcdxy}.  Affine matrix $\mathbf{H}_A$ is formed using Equation~\ref{Eqn:top_level}.  A reference $w$ x $h$ = 33x33 grid centered on the origin is transformed using these affine coordinates to a 33x33 grid centerd on the object of interest using the affine transformation also given in Equation~\ref{Eqn:top_level}.  This can be seen in Figure~\ref{Fig:affine_warping}.

\subsubsection{Compute pixel intensities at warped grid-points}
%------------------------------------------------------------
The final step is to read off the pixel intensity values at the affinely warped grid obtained in the step above.  Most of these grid points will not have integer values.  Rounding to integer values will create artefacts.  Some form of interpolation will be required to read sub-pixel intensities.  In our experiments, we use bilinear interpolation. 


%----------------------------------
\subsection{Experiment 2, Inverse affine transform}
%----------------------------------
In this experiment, we assume that we have some feature points on the object of interest as shown in Figure~\ref{fig:original_feature_points}.  Our goal is to be able to plot these points on the warped output image from Experiment 1.  For this, we need to inverse warp these points.  A point $(X,Y)$ can be inverse mapped to $(x,y)$ using

\begin{equation}
\left[\begin{array}{ccc}
x 
\\ 
y
\end{array}
\right]
=
\left[\begin{array}{ccc}
a & b\\ 
c & d
\end{array}
\right]^{-1}
\left[\begin{array}{ccc}
X - t_x  
\\ 
Y - t_y
\end{array}
\right]
\end{equation}

This causes the inverse mapped feature points to be zero-centered.  Add half width and half height ($w/2, h/2$ for even sized grids, $(w-1)/2, (h-1)/2$ for odd sized grids) to the x and y coordinates to center on the warped image.  The code for this experiment is also given in Listing~\ref{lst:demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation}.





%================================
\section{Results}
%================================
Figure~\ref{Fig:affine_warping} shows the result of affine warping to compute grid points and bilinear interpolation to compute pixel intensities.  We see that the affine region of interest accurately samples the object of interest and minimizes inclusion of background pixels.  Also, bilinear interpolation produces an accurate representation of the target of interest.  Also shown are other outputs for a set of random perturbations of our affine parameters.  These outputs can for instance be candidate samples for a particle filter.  Finally, feature points on the original image can be inversely mapped to the warped image.

%================================
\section{Conclusions}
%================================
Affine warping is an effective way of downsampling an object of interest as well as allowing a region of interest to be defined that minimizes inclusion of background pixels.  Feature points on the orignal image can be inverse warped on the output image.


%-----------------------------------------------------------------
\newpage
\appendix
\section{Source code}
\label{Sec:sourceCode}
%-----------------------------------------------------------------
\scriptsize

\lstinputlisting[language=Matlab, caption={demo\_UTIL\_2D\_coordinateAffineWarping\_and\_IntensityInterpolation.m}, 		label=lst:demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation]			{demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_coordinateAffineWarping\_and\_IntensityInterpolation.m}, 		label=lst:UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation]			{UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_apply\_transform.m}, 		label=lst:UTIL_2D_affine_apply_transform]		{UTIL_2D_affine_apply_transform.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_apply\_inverse\_transform.m}, label=lst:UTIL_2D_affine_apply_inverse_transform]		{UTIL_2D_affine_apply_inverse_transform.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_Ha\_2x3\_from\_abcdxy.m}, 	label=lst:UTIL_2D_affine_Ha_2x3_from_abcdxy]	{UTIL_2D_affine_Ha_2x3_from_abcdxy.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_abcdtxty\_to\_tllpxy.m.}, 	label=lst:UTIL_2D_affine_abcdxy_to_tllpxy]		{UTIL_2D_affine_abcdxy_to_tllpxy.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_tllpxy\_to\_abcdxy.m.}, 		label=lst:UTIL_2D_affine_tllpxy_to_abcdxy]		{UTIL_2D_affine_tllpxy_to_abcdxy.m}
\lstinputlisting[language=Matlab, caption={UTIL\_2D\_make\_rotation\_matrix.m}, 			label=lst:UTIL_2D_make_rotation_matrix]			{UTIL_2D_make_rotation_matrix.m}

\normalsize
\bibliographystyle{ieee}
\bibliography{MyCitations}
\end{document}