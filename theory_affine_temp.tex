\include{begin_article}
\title{Affine Warping in $\mathbb{R}^2$}
\author{Salman Aslam\\ Georgia Institute of Technology}
\date{}
\include{inkscapeLatex}
\begin{document}
\maketitle
\rule[0pt]{\textwidth}{1pt}
\tableofcontents
\rule[0pt]{\textwidth}{1pt}
%================================
\section{Introduction}
%================================
In many situations, it is necessary to track a visual target that is undergoing deformations.  Several targets of interest fall in this category, particularly non-rigid targets such as humans.  Even rigid objects can undergo severe deformation in a matter of seconds as shown in Figure~\ref{Fig:PETS2001_deformation}.  


								\begin{figure}
								\centering
								\subfigure[Frame 770.]{\includegraphics[width=0.45\textwidth]{figs/PETS2001_00770.jpg}}
								\subfigure[Frame 1770.]{\includegraphics[width=0.45\textwidth]{figs/PETS2001_01770.jpg}}
								\caption{Over time, even rigid objects can undergo severe deformations such as the car in these images from the PETS2001 dataset.}
								\label{Fig:PETS2001_deformation}
								\end{figure}

In such cases, using a rigid rectangular bounding box to represent the target will inevitably lead to inclusion of background pixels in the matching process.  This can easily lead to tracker drift, particularly if the tracker is also trying to learn the appearance model of the target.

We now show how to use affine warping of the rectangular bounding box so that it more closely captures the outline of the target of interest.  This minimizes inclusion of background pixels in the matching process and leads to more robust tracking.

%================================
\section{Theory}
%================================
Table \ref{table:2Dtransformations} shows different kinds of 2D linear transformations.  Every transformation generalizes the transformation below it in the table.  In this report, we are interested in the 2D affine transform since it is flexible enough to account for most distortions in real images.

								\begin{table}[t]
								\centering
								\begin{tabular}{| l | c | c | p{2.5in} |}
								\hline
								Transformation & DoF & Matrix & Distortion\\ \hline 
								& & & \\ Projective & 8 & $\ProjMatrix$ & any arbitrary quadrilateral as long as no three points are collinear\\  & & & \\ \hline
								& & & \\ Affine & 6 & $\AffMatrix$ & rotation and non-isotropic scaling\\  & & & \\ \hline
								& & & \\ Similarity & 5 & $\SimMatrix$ & scaling and rigid motion\\  & & & \\ \hline
								& & & \\ Euclidean & 4 & $\EucMatrix$ & rigid motion (rotation, translation) \\  & & & \\ \hline
								\end{tabular}\
								\caption{2D transformations}
								\label{table:2Dtransformations}
								\end{table}

The affine transform\footnote{The notation adopted by some books for the affine transform is,

\begin{equation}
\begin{array}{llllllll}
X &= ax + by + e\\
Y &= cx + dy + f
\end{array}
\label{Eq:AffineDecomposition}
\end{equation}

where the input coordinate (x,y) has been transformed through 6 affine parameters, $a, b, c, d, e, f$ to the output coordinate $(X,Y)$.  Instead of $e$ and $f$, we will be using $t_x$ and $t_y$ respectively.}
 is given by,

\begin{equation}
\begin{array}{cllll}
\left[\begin{array}{l}\acute{x}\\\acute{y}\\1\end{array}\right]   &=& \AffMatrix \left[\begin{array}{l}x\\y\\1\end{array}\right]\\
\mathbf{\acute{x}} &=& \left[\begin{array}{cccc}\mathbf{A} & \mathbf{t}\\\mathbf{0}^T & 1\end{array}\right] \mathbf{x}\\
&=& \mathbf{A}\mathbf{x} + \mathbf{t}\\
&=& \mathbf{H}_A \mathbf{x}\\
\end{array}
\label{Eqn:top_level}
\end{equation}

$t_x$ and $t_y$ are translations in the $x$ and $y$ directions respectively and $\mathbf{H}_A$ is the affine transformation matrix.  The matrix $\mathbf{A}$ above can always be decomposed using the SVD decomposition as the product of orthonormal matrix $\mathbf{U}$ containing the eigenvectors of $\mathbf{A}\mathbf{A}^T$, orthonormal matrix $\mathbf{V}$ containing the eigenvectors  $\mathbf{A}^T\mathbf{A}$ and a diagonal matrix $\mathbf{S}$ containing the eigenvalues of $\mathbf{A}$~\cite{2004_BOOK_CG_Hartley}:

\begin{equation}
\begin{array}{llllllll}
\mathbf{A} &= \left[\begin{array}{lll}a & b \\ c & d\\ \end{array}\right] \\
&=\mathbf{U}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t} \\
&={\color{blue}(\mathbf{U}\mathbf{V}^t)}{\color{red}\mathbf{V}}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t}\\
&={\color{blue}\mathbf{R}(\theta)}{\color{red}\mathbf{R}(-\phi)}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{R} (\phi)}\\
&={\color{blue}\RotMatrixTheta}{\color{red}\RotMatrixminusPhi}{\color{darkgreen}\EigenvalueMatrix}{\color{red}\RotMatrixPhi}\\\\
\end{array}
\label{Eq:AffineDecomposition}
\end{equation}

${\color{blue}\mathbf{U}\mathbf{V}^t}$ is an orthogonal matrix since $({\color{blue}\mathbf{U}\mathbf{V}^t})^t =({\color{blue}\mathbf{U}\mathbf{V}^t})^{-1}$.  Therefore, without loss of generality, it can be written as a rotation matrix.  Of the possible 6 DOFs (degrees of freedom) of the affine transformation, the 4 DOFs in $\mathbf{A}$, i.e., ($a, b, c$, $d$) have been replaced with $(\theta, \lambda_1, \lambda_2, \phi)$.

The affine matrix $\mathbf{A}$ can therefore be viewed as a succession of the following 4 steps:

\begin{enumerate} 
\item Rotation by angle $\phi$ 
\item This rotation is followed by a scaling of $\lambda_1$ and $\lambda_2$ in the rotated $x$ and $y$ directions
\item A rotation by angle -$\phi$ which brings the scaled object back to its original orientation
\item A rotation by angle $\theta$
\end{enumerate}

\subsection{\underline{Converting $(a, b, c, d)$ to $(\theta, \lambda_1, \lambda_2, \phi)$}}
\label{sec:abcd_to_tllp}
%-------------------------------------------------
In several cases, the affine parameters are given in the form of $(a, b, c, d)$.  However, it is difficult to get a physical intuition when the parameterization is done in this form.  In such cases, converting to $(\theta, \lambda_1, \lambda_2, \phi)$ helps in getting an insight into how the object of interest is being deformed.  For this step, first compute the SVD decomposition $\mathbf{A}=\mathbf{U}{\color{darkgreen}\mathbf{S}}{\color{red}\mathbf{V}^t}$.  

The first parameter, angle $\phi$, is computed as follows,

%%%CAUTION: RECONCILE THIS WITH CODE%%%
\begin{equation}
\begin{array}{ccccll}
&{\color{red}\mathbf{R}(\phi)}&=&{\color{red}\mathbf{V}^T}\\
\Rightarrow &{\color{red}\RotMatrixPhi} &=& \left[\begin{array}{llll}v_{1,1} &v_{2,1}\\v_{1,2} & v_{2,2}\end{array}\right]\\
\end{array}
\end{equation}

Therefore,

\begin{equation}
\boxed{\phi = \tan^{-1}\frac{v_{1,2}}{v_{1,1}}}
\end{equation}

The second and third parameters, scaling factors $\lambda_1$ and $\lambda_2$, are computed as follows,

\begin{equation}
\begin{array}{ccccc}
&{\color{darkgreen}\EigenvalueMatrix} &=&{\color{darkgreen}\mathbf{S}}\\
&&=&\left[\begin{array}{cccc}s_{1,1} & 0\\0 &s_{2,2}\end{array}\right]\\
\end{array}
\end{equation}

Therefore,

\begin{equation}
\boxed{
\begin{array}{cccc}
\Rightarrow \lambda_1 &=&  s_{1,1}\\
\Rightarrow \lambda_2 &=& s_{2,2}
\end{array}}
\end{equation}

The fourth parameter, angle $\theta$, is computed as follows,  

\begin{equation}
\begin{array}{ccccc}
{\color{blue}\mathbf{R}(\theta)} &=&  {\color{blue}\mathbf{U}\mathbf{V}^T}\\
{\color{blue}\RotMatrixTheta} &= &\left[\begin{array}{llll}u_{1,1} & u_{1,2}\\u_{2,1} & u_{2,2}\end{array}\right]\left[\begin{array}{llll}v_{1,1} & v_{2,1}\\v_{1,2} & v_{2,2}\end{array}\right] \\
\end{array}
\end{equation}


Therefore,

\begin{equation}
\boxed{\theta = \tan^{-1}\frac{u_{2,1}v_{1,1} + u_{2,2}v_{1,2}}{u_{1,1}v_{1,1} + u_{1,2}v_{1,2}}}
\end{equation}

The code for this step is given in Listing~\ref{lst:UTIL_2D_affine_abcdxy_to_tllpxy}.

\subsection{\underline{Converting  $(\theta, \lambda_1, \lambda_2, \phi)$ to $(a, b, c, d)$}}
%-------------------------------------------------
In visual tracking, the initial target planar bounding region is more intuitively expressed in terms of $(\theta, \lambda_1, \lambda_2, \phi)$ than in terms of $(a, b, c, d)$.  However, the actual affine warp is more easily carried out using matrix multiplication for which we need $(a, b, c, d)$.  This can be done by multiplying out all the terms in Equation~\ref{Eq:AffineDecomposition} to get

\begin{equation}
\boxed{
\begin{array}{llll}
a &= (\lambda_2) m + (\lambda_1) n\\
b &= (\lambda_2) p  - (\lambda_1) o \\
c &= (\lambda_2) o  - (\lambda_1) p \\
d &= (\lambda_2) n +(\lambda_1) m
\end{array}}
\label{Eqn:tllpxy_to_abcdxy}
\end{equation}

								\begin{figure}
								\centering
								\fbox{
								\includegraphics[width=0.75\textwidth]{figs/GRAPHICS_2D_left_turn.pdf}
								}
								\caption{Turning clockwise (left turn) in $\mathbb{R}^2$.}
								\label{fig:left_turn}
								\end{figure}


%\begin{equation}
%\begin{array}{llll}
%\mathbf{A} &= \left[\begin{array}{lll}a & b \\ c & d\\ \end{array}\right]\\
%&=\bigMatrixTwo
%\end{array}
%\end{equation}

where temporary variables $m, n, o, p$ are computed from angles $\theta$ and $\phi$ using,

\begin{equation*}
\begin{array}{llll}
\mathrm{ccc} &= \cos(\theta) \cos^2(\phi)\\
\mathrm{ccs} &= \cos(\theta) \cos(\phi) \sin(\phi)\\
\mathrm{css} &= \cos(\theta) \sin^2(\phi)\\
\mathrm{scc} &= \sin(\theta) \cos^2(\phi) \\
\mathrm{scs} &= \sin(\theta) \cos(\phi) \sin(\phi)\\
\mathrm{sss} &= \sin(\theta) \sin^2(\phi)\\
m   &=  \mathrm{css} - \mathrm{scs}\\
n  &=  \mathrm{ccc} + \mathrm{scs}\\
o   &= \mathrm{ccs} + \mathrm{sss}\\
p   &=  \mathrm{ccs} - \mathrm{scc}\\
\end{array}
\end{equation*}

The code for this step is given in Listing~\ref{lst:UTIL_2D_affine_tllpxy_to_abcdxy}.

								\begin{figure}[t]
								\centering
								\subfigure[Input: image, user defined bounding box and feature points.]{\includegraphics[width=0.65\textwidth]{figs/dataset_Dudek_with_feature_points_00001.pdf}}\\
								\subfigure[Desired output.]{\includegraphics[width=0.25\textwidth]{figs/dataset_Dudek_desired_00001.pdf}}
								\caption{The goal is to scale and warp a user defined object of interest and corresponding feature points in an image to an upright reference position.}
								\label{Fig:goal}
								\end{figure}

%------------------
\subsection{Alternate representation for $(\theta, \lambda_1, \lambda_2, \phi)$: $(\theta, s, r, \phi)$}
%------------------
At times, it is required that scaling $s=\lambda_1$ in one direction be specified explicity, but scaling in the other direction be specified as a multiple of this first scaling, i.e., $r=\frac{\lambda_2}{\lambda_1}$.  In this representation, $s$ represents scaling in the $x$ direction while $r$ represents aspect ratio.  There are still 6 DOFs.  The advantage of this representation is that in some cases, it can be more intuitive to think in terms of aspect ratio.  

Conversion from $(\theta, \lambda_1, \lambda_2, \phi)$ to $(\theta, r, s, \phi)$ can be carried out using $s=\lambda_1$ and $r=\frac{\lambda_2}{\lambda_1}$.  The reverse conversion can be done using $\lambda_1=s$ and $\lambda_2=rs$.

%================================
\section{Experiments}
%================================
For our experiments, consider Figure~\ref{Fig:goal}.  The goal is to scale and warp a user defined object of interest and corresponding feature points to an upright position.  To achieve our goal, we design 2 experiments.  The goal of the first experiment is to warp and scale the actual image and the goal of the second experiment is to warp and scale the feature points.

Before we explain the experiments in detail, we discuss the overall idea.  Ideally, we could apply an inverse affine transform and be done with it.  There is one challenge though.  We do not know the pixel coordinates of every point inside the bounding region.  To deal with this, we design experiment 1 in which we take a rectangular grid whose coordinates we know, warp it using our affine parameters to cover the object of interest, interpolate image intensities on those points to create an upright scaled output image.  For the feature points, we do know their pixel coordinates and so in experiment 2, we straight away apply the inverse affine transform to compute their new positions in the output image.  So, in summary,

								\begin{figure}[t]
								\centering
								\fbox{\includegraphics[width=0.85\textwidth]{figs/dataset_Dudek_00001_forwardAffine.pdf}}
								\caption{Experiment 1, Dudek dataset, frame 1, application of the forward affine transform.  In this experiment, we warp an arbitrary zero-centered grid to a grid covering the object of interest.  The dimensions of the object of interest, the face, are 110x130 (width x height).  The dimensions of the warped output grid are 33x33.  Notice that the density of grid points is greater in the horizontal direction.}
								\label{fig:experiment1}
								\end{figure}



\begin{enumerate}
\item \underline{Experiment 1}: Forward affine transform to extract object of interest from original image
\begin{enumerate}
\item Warp user-defined grid using affine-parameter initialization to sample object of interest
\item Interpolate pixel intensities at warped grid-points.
\end{enumerate}
\item \underline{Experiment 2}: Inverse affine transform to warp feature points on original image to warped image.
\item \underline{Experiment 3}: Randomize affine parameters to generate several warped sub-images.
\end{enumerate}


Before explaining these experiments in detail, we take a brief digression to explain how to compute affine parameters of the object of interest.

The source code for all these steps is given in Listing~\ref{lst:demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation}.

%------------------------------------------------------------
\subsection{Computing affine parameters of manually initialized object}
%------------------------------------------------------------

An object of interest in an image can be manually specified by drawing a bounding box around it, and then rotating the bounding box so that it reasonably encloses the object.  This step is relatively straightforward to do in standard image processing software.  In most cases, this rigid representation, as opposed to an affine representation, will suffice to reasonably enclose the object of interest for the purposes of initialization.  This requires 5 parameters for complete specification:

\begin{enumerate}
\item $t_x$, bounding box center x coordinate
\item $t_y$, bounding box center y coordinate
\item $w$, width of bounding box
\item $h$, height of bounding box
\item $\theta$, rotation angle of bounding box in radians.  In the cartesian coordinate system, a positive $\theta$ corresponds to counter-clockwise direction.  This can be verified quickly since a $90^{\circ}$ left turn for a vector $(x,y)^T$ in $\mathbb{R}^2$ is given by $(-y,x)^T$.  This is obtained using,


\begin{equation}
\left[\begin{array}{ccc}
-y 
\\ 
x
\end{array}
\right]=
\left[
\begin{array}{rrr}
\cos(90^{\circ}) & -\sin(90^{\circ}) \\
\sin(90^{\circ}) & \cos(90^{\circ})
\end{array}
\right]
\left[\begin{array}{ccc}
x 
\\ 
y
\end{array}
\right]
\end{equation}

								\begin{figure}[t]
								\centering
								\includegraphics[width=0.75\textwidth]{figs/dataset_Dudek_00001_inverseAffine.pdf}
								\caption{Experiment 2, Dudek dataset, frame 1, application of inverse affine transform.  In this experiment, we apply the inverse affine transform to warp a set of given feature points and place them on Grid B from Figure~\ref{fig:experiment1}.}
								\label{fig:experiment2}
								\end{figure}


The term "left turn" is commonly used in computer graphics.  In  $\mathbb{R}^2$, it corresponds to a counter-clockwise rotation.  In images, where the $y$ coordinate normally decreases vertically downwards, a left turn is given by $(y,-x)^T$.  Notice that $(x,y)^T(-y,x) = (x,y)^T(y,-x) = 0$, and therefore both $ (-y,x)^T$ and $(y,-x)^T$ are orthogonal to $(x,y)^T$.  See Figure~\ref{fig:left_turn} for a graphical representation.
\end{enumerate}

As an example, consider Figure~\ref{fig:experiment1}.  We are interested in segmenting the face.  The initial parameters are: $t_x=188, t_y=192, w=110, h=130, \theta=-4.58^\circ$.  Note that we specify angles in radians.  $\theta$ is written here in degrees for clarity.  Moreover, notice that the bounding box is rotated in the counter-clockwise direction.  Since the y axis increases downwards, $\theta$ is negative.

Once we have an initial rigid representation of the object of interest, we can transform this representation into an affine representation.  Since the affine representation allows for scaling, we can scale the object and obtain its segmentation in scaled form.  For instance, in Figure~\ref{fig:experiment1}, the dimensions of the object of interest are 110x130.  However, for computational efficiency, we want the dimensions to be 33x33.  The affine parameters then become $\theta=-4.58^\circ, \lambda_1=110/32=3.4375, \lambda_2=130/32=4.0625, \phi=0^\circ, t_x=188, t_y=192$.  \footnote{Notice that we have divided by 32 instead of 33.  The reason is that the grid used in~\cite{2008_JNL_subspaceTRK_Ross} is 32x32 and they have accordingly used a divisor of 32.  In our case, for RVQ we require an odd dimensional grid due to the way the closed source codebook encoding software, gen.exe is setup.  Therefore, we pick a 33x33 grid.  Not changing the divisor to 33 was an oversight but this omission is expected to have minimal effect on results.}


%----------------------------------
\subsection{Experiment 1: Forward affine transform}
%----------------------------------
In this experiment, our goal is to extract an object of interest from an original image, scale it and make it upright.  We start with an arbitrary zero-centered grid, grid A as shown in Figure~\ref{fig:experiment1}.  The forward affine transform is applied to this grid so that it covers the object of interest and is now called grid B.  Note that the dimensions of grid B are also 33x33.  Grid B is now placed at coordinates (1,1) so that its coordinates go from 1 to 33 in the horizontal direction and 1 to 33 in the vertical direction.  Note that this grid now samples the object of interest.  This grid is then placed at the origin as shown in Figure~\ref{fig:experiment2}.  

\subsubsection{Warp user-defined grid}
%------------------------------------------------------------
In this step, the affine parameters $(\theta, \lambda_1, \lambda_2, \phi, t_x, t_y)$ computed above are changed to $(a, b, c, d, t_x, t_y)$ using Equation~\ref{Eqn:tllpxy_to_abcdxy}.  Affine matrix $\mathbf{H}_A$ is formed using Equation~\ref{Eqn:top_level}.  A reference $w$ x $h$ = 33x33 grid centered on the origin is transformed using these affine coordinates to a 33x33 grid centerd on the object of interest using the affine transformation also given in Equation~\ref{Eqn:top_level}.  This can be seen in Figure~\ref{fig:experiment1}.

\subsubsection{Interpolate pixel intensities}
%------------------------------------------------------------
The final step is to read off the pixel intensity values at the affinely warped grid obtained in the step above.  Most of these grid points will not have integer values.  Rounding to integer values will create artefacts.  Some form of interpolation will be required to read sub-pixel intensities.  In our experiments, we use bilinear interpolation. 


%----------------------------------
\subsection{Experiment 2, Inverse affine transform}
%----------------------------------
Now, feature points on the original Figure are inverse-affine-transformed and superimposed on grid B.  A feature point with coordinates $(X,Y)$ can be inverse affine mapped to $(x,y)$ using

\begin{equation}
\left[\begin{array}{ccc}
x 
\\ 
y
\end{array}
\right]
=
\left[\begin{array}{ccc}
a & b\\ 
c & d
\end{array}
\right]^{-1}
\left[\begin{array}{ccc}
X - t_x  
\\ 
Y - t_y
\end{array}
\right]
\end{equation}

For our example, the initial feature points are 


								\begin{figure}[t]
								\centering
								\includegraphics[width=0.65\textwidth]{figs/affineCandidates.pdf}
								\caption{Experiment 3.  Different affine parameters will produce different 33x33 outputs.}
								\label{fig:experiment3}
								\end{figure}


\begin{equation*}
\left[\begin{array}{ccc}
X  
\\ 
Y
\end{array}
\right]=
\left[
\begin{array}{cccccccc}
148.9306 & 187.2747 & 226.0674 & 169.6408 & 192.6433 & 218.8531 & 194.5372\\
179.0198 & 172.5994 & 174.0397 & 230.2172 & 224.5582 & 223.3328 & 243.8089\\
\end{array}
\right]
\end{equation*}

Applying the inverse affine transform yields

\begin{equation*}
\left[\begin{array}{ccc}
x  
\\ 
y
\end{array}
\right]=
\left[
\begin{array}{rrrrrrrrrrr}
  -11.0275 &   0.2407 &  11.4563 &  -6.2122  &  0.5896 &   8.2183 &   0.6912\\
   -3.9534  & -4.7745  & -3.6580  &  9.0161  &  8.0800  &  8.2949  & 12.8408
\end{array}
\right]
\end{equation*}


Notice that the inverse mapped feature points are zero-centered.  We add $(w/2, h/2)$ so that these warped feature points correctly align with grid B whose first x and y coordinate is at (1,1).\footnote{This uses Matlab notation rather than C++ notation where the first x and y coordinates are at (0,0).}  This gives,

\begin{equation*}
\left[\begin{array}{ccc}
x  
\\ 
y
\end{array}
\right]=
\left[
\begin{array}{rrrrrrrrrrr}
   5.4725  & 16.7407 &  27.9563  & 10.2878  & 17.0896 &  24.7183  & 17.1912 \\
   12.5466 &  11.7255 &  12.8420 &   25.5161 &  24.5800  & 24.7949 &   29.3408
\end{array}
\right]
\end{equation*}

These points are plotted in Figure~\ref{fig:experiment2}.

%----------------------------------
\subsection{Experiment 3, Random warps}
%----------------------------------
In many cases, it is required to randomize the affine parameters and generate sub-images from a given object.  In the particle filter, for instance, this can be used to generate particles, also called samples or candidates.  This is show in Figure~\ref{fig:experiment3}.

We start with the following standard deviations for our $(\theta, \lambda_1, \lambda_2, \phi, t_x, t_y)$ parameters:

\begin{equation*}
\left[\begin{array}{ccc}
\sigma_\theta \vspace{0.1in}\\
\sigma_{\lambda_1} \vspace{0.1in}\\
\sigma_{\lambda_2} \vspace{0.1in}\\
\sigma_\phi \vspace{0.1in}\\
\sigma_{t_x} \vspace{0.1in}\\
\sigma_{t_y} \vspace{0.1in}\\
\end{array}
\right]=
\left[
\begin{array}{lllllllllll}
0.05\vspace{0.1in}\\
0.05\vspace{0.1in}\\
0.005\vspace{0.1in}\\
0.001\vspace{0.1in}\\
9\vspace{0.1in}\\
9\vspace{0.1in}\\
\end{array}
\right]
\end{equation*}

Each standard deviation above is used to generate one 600-sample gaussian distribution with that standard deviation.


\begin{equation*}
\left[
\begin{array}{rrrrrrrr}
    0.5397\\
    3.0467\\
   -0.7489\\
    0.1194\\
    0.5592\\
    1.0785\\
\end{array}
\right]
\end{equation*}

The standard deviations are multiplied with the respective standard deviation values 



%================================
\section{Results}
%================================
Figure~\ref{fig:experiment1} shows the result of affine warping to compute warped grid points and bilinear interpolation to compute pixel intensities on those warped grid points to produce an upright scaled image.  We see that the affine region of interest accurately samples the object of interest and minimizes inclusion of background pixels.  Also, bilinear interpolation produces an accurate representation of the target of interest.  The original feature points are also correctly warped and overlaid on the output image.

%================================
\section{Conclusions}
%================================
Affine warping is an effective way of extracting an object of interest and associated feature points from a given image.  The affine representation is rich enough to bound many objects of interest while minimizing inclusion of background pixels.




%%-----------------------------------------------------------------
%\newpage
%\appendix
%\section{Source code}
%\label{Sec:sourceCode}
%%-----------------------------------------------------------------
%\scriptsize
%
%\lstinputlisting[language=Matlab, caption={demo\_UTIL\_2D\_coordinateAffineWarping\_and\_IntensityInterpolation.m}, 		label=lst:demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation]			{demo_UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_coordinateAffineWarping\_and\_IntensityInterpolation.m}, 		label=lst:UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation]			{UTIL_2D_coordinateAffineWarping_and_IntensityInterpolation.m}
%
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_grid\_create.m}, 						label=lst:UTIL_2D_grid_create]							{UTIL_2D_grid_create.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_make\_rotation\_matrix.m}, 				label=lst:UTIL_2D_make_rotation_matrix]					{UTIL_2D_make_rotation_matrix.m}
%
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_apply\_transform.m}, 			label=lst:UTIL_2D_affine_apply_transform]				{UTIL_2D_affine_apply_transform.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_apply\_inverse\_transform.m}, 	label=lst:UTIL_2D_affine_apply_inverse_transform]		{UTIL_2D_affine_apply_inverse_transform.m}
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_xywht\_to\_tllpxy.m}, 			label=lst:UTIL_2D_affine_xywht_to_tllpxy]				{UTIL_2D_affine_xywht_to_tllpxy.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_xywht\_to\_Ha\_2x3.m}, 		label=lst:UTIL_2D_affine_xywht_to_Ha_2x3]				{UTIL_2D_affine_xywht_to_Ha_2x3.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_Ha\_2x3\_from\_abcdxy.m}, 	label=lst:UTIL_2D_affine_Ha_2x3_from_abcdxy]			{UTIL_2D_affine_Ha_2x3_from_abcdxy.m}
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_tllpxy\_to\_abcdxy.m.}, 			label=lst:UTIL_2D_affine_tllpxy_to_abcdxy]				{UTIL_2D_affine_tllpxy_to_abcdxy.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_abcdxy\_to\_tllpxy.m.}, 			label=lst:UTIL_2D_affine_abcdxy_to_tllpxy]				{UTIL_2D_affine_abcdxy_to_tllpxy.m}
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_tllpxy\_to\_tsrpxy.m.}, 			label=lst:UTIL_2D_affine_tllpxy_to_tsrpxy]				{UTIL_2D_affine_tllpxy_to_tsrpxy.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_tsrpxy\_to\_tllpxy.m.}, 			label=lst:UTIL_2D_affine_tsrpxy_to_tllpxy]				{UTIL_2D_affine_tsrpxy_to_tllpxy.m}
%
%\newpage
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_tsrpxy\_to\_abcdxy.m.}, 			label=lst:UTIL_2D_affine_tsrpxy_to_abcdxy]				{UTIL_2D_affine_tsrpxy_to_abcdxy.m}
%\lstinputlisting[language=Matlab, caption={UTIL\_2D\_affine\_abcdxy\_to\_tsrpxy.m.}, 			label=lst:UTIL_2D_affine_abcdxy_to_tsrpxy]				{UTIL_2D_affine_abcdxy_to_tsrpxy.m}
    
    

    
    





\normalsize
\bibliographystyle{ieee}
\bibliography{MyCitations}
\end{document}